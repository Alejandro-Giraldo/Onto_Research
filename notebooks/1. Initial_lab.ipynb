{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06279685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alejandro.gl\\Documents\\_projects\\onto_research\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# PROCESAMIENTO DE DATOS\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# KGs\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "# AGENTES Y ORQUESTACIÓN\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "\n",
    "# DISPLAYS AND IMAGES\n",
    "from IPython.display import Image, display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795ba36",
   "metadata": {},
   "source": [
    "### Procesamiento de Grafos de Conocimiento\n",
    "\n",
    "**Objetivo:**\n",
    "# \n",
    "Desarrollar un sistema eficiente para transformar datos no estructurados en grafos de conocimiento, que sirvan como base para agentes inteligentes.\n",
    "\n",
    "**Fases del Proceso:**\n",
    "\n",
    "1. **Transformación de Datos:**\n",
    "   - 1.1 Convertir datos no estructurados en grafos de conocimiento.\n",
    "   - 1.2 Utilizar grafos de conocimiento como fuente de información para agentes.\n",
    "   - 1.3 Implementar grafos de conocimiento como sistemas de memoria para agentes (en desarrollo).\n",
    "\n",
    "2. **KG-Consumer:**\n",
    "   - Arquitectura de agente reflexivo diseñado para consumir, analizar y responder preguntas de manera crítica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e8556",
   "metadata": {},
   "source": [
    "#### Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a342580",
   "metadata": {},
   "source": [
    "##### Components\n",
    "\n",
    "- Modelo y Embedings: `Llama 3.2`\n",
    "- PDF Loaders (Docling), Chunks & Splitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1c8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\", temperature=0, base_url=\"http://localhost:11434\")\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\", base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a23ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# PDF reader\n",
    "path_file = \"Data/genetics-in-osteoarthritis.pdf\"\n",
    "loader = DoclingLoader(file_path=path_file)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e584f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting -Chunking\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=200).split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fec333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Osteoarthritis  is  a  degenerative  articular  disease  with  a complex pathogeny because diverse factors interact causing a  process  of  deterioration  of  the  cartilage  and  the  subchondral bone. It can be primary or secondary to diverse diseases, but it has  clinical, radiological,  and pathological manifestations in common. Its pathogenesis is complex due to genetic, metabolic and local factors, which interact and cause a process of deterioration of the cartilage, with a proliferative reaction  of  subchondral  bone  and  synovial  inflammation.  Apart from the classical  concept  of"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chunks[5].page_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb13a1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of 135\n",
      "Processing chunk 2 of 135\n",
      "Processing chunk 3 of 135\n",
      "Processing chunk 4 of 135\n",
      "Processing chunk 5 of 135\n",
      "Processing chunk 6 of 135\n",
      "Processing chunk 7 of 135\n",
      "Processing chunk 8 of 135\n",
      "Processing chunk 9 of 135\n",
      "Processing chunk 10 of 135\n",
      "Processing chunk 11 of 135\n",
      "Processing chunk 12 of 135\n",
      "Processing chunk 13 of 135\n",
      "Processing chunk 14 of 135\n",
      "Processing chunk 15 of 135\n",
      "Processing chunk 16 of 135\n",
      "Processing chunk 17 of 135\n",
      "Processing chunk 18 of 135\n",
      "Processing chunk 19 of 135\n",
      "Processing chunk 20 of 135\n",
      "Processing chunk 21 of 135\n",
      "Processing chunk 22 of 135\n",
      "Processing chunk 23 of 135\n",
      "Processing chunk 24 of 135\n",
      "Processing chunk 25 of 135\n",
      "Processing chunk 26 of 135\n",
      "Processing chunk 27 of 135\n",
      "Processing chunk 28 of 135\n",
      "Processing chunk 29 of 135\n",
      "Processing chunk 30 of 135\n",
      "Processing chunk 31 of 135\n",
      "Processing chunk 32 of 135\n",
      "Processing chunk 33 of 135\n",
      "Processing chunk 34 of 135\n",
      "Processing chunk 35 of 135\n",
      "Processing chunk 36 of 135\n",
      "Processing chunk 37 of 135\n",
      "Processing chunk 38 of 135\n",
      "Processing chunk 39 of 135\n",
      "Processing chunk 40 of 135\n",
      "Processing chunk 41 of 135\n",
      "Processing chunk 42 of 135\n",
      "Processing chunk 43 of 135\n",
      "Processing chunk 44 of 135\n",
      "Processing chunk 45 of 135\n",
      "Processing chunk 46 of 135\n",
      "Processing chunk 47 of 135\n",
      "Processing chunk 48 of 135\n",
      "Processing chunk 49 of 135\n",
      "Processing chunk 50 of 135\n",
      "Processing chunk 51 of 135\n",
      "Processing chunk 52 of 135\n",
      "Processing chunk 53 of 135\n",
      "Processing chunk 54 of 135\n",
      "Processing chunk 55 of 135\n",
      "Processing chunk 56 of 135\n",
      "Processing chunk 57 of 135\n",
      "Processing chunk 58 of 135\n",
      "Processing chunk 59 of 135\n",
      "Processing chunk 60 of 135\n",
      "Processing chunk 61 of 135\n",
      "Processing chunk 62 of 135\n",
      "Processing chunk 63 of 135\n",
      "Processing chunk 64 of 135\n",
      "Processing chunk 65 of 135\n",
      "Processing chunk 66 of 135\n",
      "Processing chunk 67 of 135\n",
      "Processing chunk 68 of 135\n",
      "Processing chunk 69 of 135\n",
      "Processing chunk 70 of 135\n",
      "Processing chunk 71 of 135\n",
      "Processing chunk 72 of 135\n",
      "Processing chunk 73 of 135\n",
      "Processing chunk 74 of 135\n",
      "Processing chunk 75 of 135\n",
      "Processing chunk 76 of 135\n",
      "Processing chunk 77 of 135\n",
      "Processing chunk 78 of 135\n",
      "Processing chunk 79 of 135\n",
      "Processing chunk 80 of 135\n",
      "Processing chunk 81 of 135\n",
      "Processing chunk 82 of 135\n",
      "Processing chunk 83 of 135\n",
      "Processing chunk 84 of 135\n",
      "Processing chunk 85 of 135\n",
      "Processing chunk 86 of 135\n",
      "Processing chunk 87 of 135\n",
      "Processing chunk 88 of 135\n",
      "Processing chunk 89 of 135\n",
      "Processing chunk 90 of 135\n",
      "Processing chunk 91 of 135\n",
      "Processing chunk 92 of 135\n",
      "Processing chunk 93 of 135\n",
      "Processing chunk 94 of 135\n",
      "Processing chunk 95 of 135\n",
      "Processing chunk 96 of 135\n",
      "Processing chunk 97 of 135\n",
      "Processing chunk 98 of 135\n",
      "Processing chunk 99 of 135\n",
      "Processing chunk 100 of 135\n",
      "Processing chunk 101 of 135\n",
      "Processing chunk 102 of 135\n",
      "Processing chunk 103 of 135\n",
      "Processing chunk 104 of 135\n",
      "Processing chunk 105 of 135\n",
      "Processing chunk 106 of 135\n",
      "Processing chunk 107 of 135\n",
      "Processing chunk 108 of 135\n",
      "Processing chunk 109 of 135\n",
      "Processing chunk 110 of 135\n",
      "Processing chunk 111 of 135\n",
      "Processing chunk 112 of 135\n",
      "Processing chunk 113 of 135\n",
      "Processing chunk 114 of 135\n",
      "Processing chunk 115 of 135\n",
      "Processing chunk 116 of 135\n",
      "Processing chunk 117 of 135\n",
      "Processing chunk 118 of 135\n",
      "Processing chunk 119 of 135\n",
      "Processing chunk 120 of 135\n",
      "Processing chunk 121 of 135\n",
      "Processing chunk 122 of 135\n",
      "Processing chunk 123 of 135\n",
      "Processing chunk 124 of 135\n",
      "Processing chunk 125 of 135\n",
      "Processing chunk 126 of 135\n",
      "Processing chunk 127 of 135\n",
      "Processing chunk 128 of 135\n",
      "Processing chunk 129 of 135\n",
      "Processing chunk 130 of 135\n",
      "Processing chunk 131 of 135\n",
      "Processing chunk 132 of 135\n",
      "Processing chunk 133 of 135\n",
      "Processing chunk 134 of 135\n",
      "Processing chunk 135 of 135\n"
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "# Embedding content\n",
    "# logica para crear los embedding de los chunks.page_content y guardarlos como parte de los metadatos.\n",
    "for i, doc in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i+1} of {len(chunks)}\")\n",
    "    doc.metadata[\"embedding\"] = embeddings.embed_query(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610e762",
   "metadata": {},
   "source": [
    "#### Persistencia y Modelo\n",
    "\n",
    "\n",
    "- Es posible almacenar la estructura de un documento para crear una topología que sirva como base en el modelo que se desea desarrollar. Por ejemplo, se puede representar mediante un patrón jerárquico las relaciones entre documentos, páginas y fragmentos (chunks).\n",
    "\n",
    "$$\n",
    "\\text{(Documento)} \\xrightarrow{\\text{HAS}} \\text{(Página)} \\xrightarrow{\\text{DIVIDED\\_INTO}} \\text{(Fragmento)}\n",
    "$$\n",
    "\n",
    "En cada nodo de esta estructura, se pueden almacenar diversos metadatos. En particular, nos interesa enriquecer los atributos asociados a los fragmentos, como los embeddings. Para lograr esto, se puede implementar una función utilizando pandas, el controlador de Neo4j y Cypher, que permita cargar los datos en un DataFrame o leer directamente los documentos para construir esta estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86773022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "URI = \"neo4j://127.0.0.1:7687\"\n",
    "PASSWORD = \"onto_research\"\n",
    "USER = \"neo4j\"\n",
    "\n",
    "def create_graph(uri, user, password):\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    return driver\n",
    "\n",
    "driver = create_graph(URI, USER, PASSWORD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d81d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Data/genetics-in-osteoarthritis.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 63.84, 't': 690.528, 'r': 525.72, 'b': 680.628, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 90]}]}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 63.84, 't': 655.567, 'r': 550.546, 'b': 633.155, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 143]}]}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 106.32, 't': 618.136, 'r': 550.502, 'b': 533.77, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 933]}]}], 'headings': ['Genetics in Osteoarthritis'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 7415910253374491953, 'filename': 'genetics-in-osteoarthritis.pdf'}}}, page_content=\"Genetics in Osteoarthritis\\nMercedes Fernández-Moreno, Ignacio Rego, Vanessa Carreira-Garcia and Francisco J. Blanco *\\nOsteoarticular  and  Aging  Research  Lab,  Genomics  Unit.  Biomedical  Research  Center,  INIBIC-CH  Universitario  A Coruña, A Coruña, Spain\\nAbstract: Osteoarthritis is a degenerative articular disease with complex pathogeny because diverse factors interact causing a process of deterioration of the cartilage. Despite the multifactorial nature of this pathology, from the 50's it´s known that certain forms of osteoarthritis are related to a strong genetic component. The genetic bases of this disease do not follow the typical patterns of mendelian inheritance and probably they are related to alterations in multiple genes. The identification of a high number of candidate genes to confer susceptibility to the development of the osteoarthritis shows the complex nature of this disease. At the moment, the genetic mechanisms of this disease are not known, however, which seems clear is that expression levels of several genes are altered, and that the inheritance will become a substantial factor in future considerations of diagnosis and treatment of the osteoarthritis.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa169e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_to_graph(driver, docs):\n",
    "    with driver.session() as session:\n",
    "        for doc in docs:\n",
    "            # Extraer datos del documento\n",
    "            document_id = doc.metadata['source']\n",
    "            page_id = f\"{doc.metadata['source']}_page_{doc.metadata['dl_meta']['doc_items'][0]['prov'][0]['page_no']}\"\n",
    "            chunk_id = f\"{doc.metadata['source']}_chunk_{hash(doc.page_content)}\"\n",
    "            chunk_content = doc.page_content\n",
    "            headings = doc.metadata['dl_meta']['headings']\n",
    "            embedding = doc.metadata['embedding']\n",
    "\n",
    "            query = \"\"\"\n",
    "            MERGE (d:Document {id: $document_id})\n",
    "            MERGE (p:Page {id: $page_id})\n",
    "            MERGE (c:Chunk {id: $chunk_id, content: $chunk_content, headings: $headings, embedding: $embedding})\n",
    "            MERGE (d)-[:HAS]->(p)\n",
    "            MERGE (p)-[:DIVIDED_IN]->(c)\n",
    "            \"\"\"\n",
    "\n",
    "            # INGEST TO GRAPH\n",
    "            session.run(query, document_id=document_id, page_id=page_id, chunk_id=chunk_id, \n",
    "                    chunk_content=chunk_content, headings=headings, embedding=embedding)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05ca04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_index(driver, index_name=\"chunk_embeddings\", dimensions=4096):\n",
    "    \"\"\"Crea vector index solo si no existe\"\"\"\n",
    "    with driver.session() as session:\n",
    "        try:\n",
    "            query = f\"\"\"\n",
    "            CALL db.index.vector.createNodeIndex(\n",
    "                '{index_name}',\n",
    "                'Chunk',\n",
    "                'embedding',\n",
    "                {dimensions},\n",
    "                'cosine'\n",
    "            )\n",
    "            \"\"\"\n",
    "            session.run(query)\n",
    "            print(\"Vector index creado\")\n",
    "        except Exception as e:\n",
    "            if \"already exists\" in str(e):\n",
    "                print(\"Vector index ya existe\")\n",
    "            else:\n",
    "                print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_text_index(driver):\n",
    "        \"\"\"Crea índice de texto simple\"\"\"\n",
    "        with driver.session() as session:\n",
    "            query = \"\"\"\n",
    "            CREATE INDEX chunk_content_text IF NOT EXISTS \n",
    "            FOR (c:Chunk) ON (c.pag_content)\n",
    "            \"\"\"\n",
    "            session.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae34b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_indexes(driver):\n",
    "    \"\"\"Configura todos los índices necesarios\"\"\"\n",
    "    create_vector_index(driver)\n",
    "    create_text_index(driver)\n",
    "    print(\"Índices creados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0149051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector index ya existe\n",
      "Índices creados\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m setup_indexes(driver)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mingest_to_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mingest_to_graph\u001b[39m\u001b[34m(driver, docs)\u001b[39m\n\u001b[32m      8\u001b[39m chunk_content = doc.page_content\n\u001b[32m      9\u001b[39m headings = doc.metadata[\u001b[33m'\u001b[39m\u001b[33mdl_meta\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mheadings\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m embedding = \u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33mMERGE (d:Document \u001b[39m\u001b[33m{\u001b[39m\u001b[33mid: $document_id})\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33mMERGE (p:Page \u001b[39m\u001b[33m{\u001b[39m\u001b[33mid: $page_id})\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m \u001b[33mMERGE (p)-[:DIVIDED_IN]->(c)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# INGEST TO GRAPH\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'embedding'"
     ]
    }
   ],
   "source": [
    "setup_indexes(driver)\n",
    "ingest_to_graph(driver, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b59a5d7",
   "metadata": {},
   "source": [
    "### Graph RAG\n",
    "\n",
    "- a. De la estructura creada del documento.\n",
    "- a.1 De la extracción de entidades que puede ejercerse sobre los page content en cada chunk.\n",
    "- b. De Grafos curados con sus debidas ontologías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c888b",
   "metadata": {},
   "source": [
    "#### Graph RAG De la estructura creada del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphSparqlQAChain # DB\n",
    "from langchain_community.graphs import RdfGraph\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8064ed3",
   "metadata": {},
   "source": [
    "## From external KG\n",
    "\n",
    "What is a \"hetnet\"?\n",
    "A network (also known as a graph) is a conceptual representation of a group of things — called nodes — and the relationships between them — called edges. Typically, a network has only one type of node and one type of edge. But in many cases, it is necessary to be able to distinguish between different types of entities and relationships.\n",
    "\n",
    "A hetnet (short for heterogeneous information network) is a network where nodes and edges can be multiple types. This additional dimension allows a hetnet to accurately describe more complex data. Hetnets are particularly useful in biomedicine, where it is important to capture the conceptual distinctions between various components and mechanisms, such as genes and diseases, or upregulation and binding.\n",
    "\n",
    "The prefix meta is used on this site to refer to the type of the node/edge (e.g. compound), as opposed to the specific node/edge itself (e.g. acetaminophen).\n",
    "\n",
    "What is Hetionet?\n",
    "Hetionet is a hetnet of biomedical knowledge. It encodes relationships uncovered by millions of studies conducted over the last half-century into a single resource. The network is constructed from a collection of publicly available databases, and is itself open-source and free to use, barring any upstream restrictions.\n",
    "\n",
    "Hetionet enables scientists and biologists to formulate novel hypotheses, predictions, and other valuable insights by connecting an existing body of biomedical data across multiple levels and types in a convenient, accessible, holistic way.\n",
    "\n",
    "Why was Hetionet made?\n",
    "Hetionet was originally created as part of Project Rephetio, a study that utilized the benefits of hetnets to predict new uses for existing drugs. Although the original resources for the network were selected for drug repurposing, Hetionet is now useful in a much broader sense, and has been used for a variety of purposes.\n",
    "\n",
    "Hetionet was also made to alleviate some of the inaccuracies and inconveniences of using other integrative networks, or trying to use multiple, separate databases in the same analysis. It unifies data from several different, disparate sources into a single, comprehensive, accessible, common-format network.\n",
    "\n",
    "What's in Hetionet?\n",
    "Hetionet combines information from 29 public databases. The network contains 47,031 nodes of 11 types and 2,250,197 edges of 24 types.\n",
    "\n",
    "Metanode\tDescription\n",
    "Gene\tProtein-coding human genes. From Entrez Gene.\n",
    "Compound\tApproved small molecule compounds with documented chemical structures. From DrugBank.\n",
    "Anatomy\tAnatomical structures, excluding structures that are known not to be found in humans. From Uberon.\n",
    "Disease\tComplex diseases, selected to be distinct and specific enough to be clinically relevant yet general enough to be well annotated. From Disease Ontology.\n",
    "Symptom\tSigns and Symptoms (i.e. clinical abnormalities that can indicate a medical condition). From the MeSH ontology.\n",
    "Side Effect\tAdverse drug reactions. From SIDER/UMLS.\n",
    "Biological Process\tLarger processes or biological programs accomplished by multiple molecular activities. From Gene Ontology.\n",
    "Cellular Component\tThe locations relative to cellular structures in which a gene product performs a function. From Gene Ontology.\n",
    "Molecular Function\tActivities that occur at the molecular level, such as \"catalysis\" or \"transport\". From Gene Ontology.\n",
    "Pathway\tA series of actions among molecules in a cell that leads to a certain product or change in the cell. From WikiPathways, Reactome, and Pathway Interaction Database.\n",
    "Pharmacologic Class\t\"Chemical/Ingredient\", \"Mechanism of Action\", and \"Physiologic Effect\" FDA class types. From DrugCentral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOLS\n",
    "hetionet_url = \"https://neo4j.het.io/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENTE GENERADOR\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data modelling expert capable of creating high quality entity-relationship models from denormalised datasets. \"\n",
    "            \"You always follow these modeling principles: \"\n",
    "            \"You don't overnormalize the model. \"\n",
    "            \"You don't use the same name for realtionships connecting different types of entities. \"\n",
    "            \"You make sure that all features in the dataset are included in the model. \"\n",
    "            \"You make sure there is a one to one mapping between the attributes in the extracted entities and the features in the dataset provided as input. \",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "model_generate = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENTE REFLECTOR\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data modelling expert capable of analysing entity-relationship models and suggest changes that can improve them. \" +\n",
    "            \"You are not supposed to generate a new model, just provide suggestions for changes when pertinent. \" +\n",
    "            \"You always pay extra attention at the following: \" +\n",
    "            \"Detect under-normalized in the model and recommend they are extracted as new entities connected to the existing ones through relevant relationships. \" +\n",
    "            \"Detect over-normalized entities in the model and recommend they are merged as part of existing ones. \" +\n",
    "            \"Suggest alternative names for terms (property names, entity names, relationship names) used in the model if the proposed ones are not adequate or expressive enough\" +\n",
    "            \"You do not recommend combining or merging attributes into composite ones. \" +\n",
    "            \"You don't always need to propose changes, if a model is good as-is just do not propose changes. \"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "model_reflect = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c73385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce275d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a116f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
